{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mercy Wangondu: Introduction to Computer Vision.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#2F4F4F'>1. Defining the Question</font>"
      ],
      "metadata": {
        "id": "kUlHdeyQ9jP0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a) Specifying the Data Analysis Question\n",
        "\n",
        "Conduct an evaluation to determine whether data science can help a supermarket chain to adhere to alcohol laws by making sure they do not sell alcohol to underage people"
      ],
      "metadata": {
        "id": "Yq4nj6qO9oiO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b) Defining the Metric for Success\n",
        "We will have succeeded if we can build a model for verifying people's age and evaluate it using Mean Absolute Error (MAE) "
      ],
      "metadata": {
        "id": "6jzgjwES9wg0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c) Understanding the context \n",
        "The supermarket chain would like to explore whether Data Science can help them adhere to\n",
        "alcohol laws by making sure they do not sell alcohol to people underage. You are asked to\n",
        "conduct that evaluation, so as you set to work, keep the following in mind:\n",
        "\n",
        "\n",
        "1.   The shops are equipped with cameras in the checkout area which are triggered when a\n",
        "person is buying alcohol.\n",
        "2.   Computer vision methods can be used to determine the age of a person from a photo.\n",
        "3. The task then is to build and evaluate a model for verifying people's age."
      ],
      "metadata": {
        "id": "Vx5ohjGa9zv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## d) Recording the Experimental Design\n",
        "\n",
        "1. Import the Data\n",
        "2. Perform exploratory data analysis to get an overall impression of the dataset.\n",
        "3. Train and evaluate the model (it needs to be done on the GPU platform).\n",
        "4. Combine your code, output, and findings (from the previous points) in the final notebook.\n",
        "5. Make conclusions of the model evaluation, add them to the notebook."
      ],
      "metadata": {
        "id": "YudzIJMN93TD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## e) Data Relevance\n",
        "The data was relevant for our analysis"
      ],
      "metadata": {
        "id": "6-8TiZwD97a7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2rSuKvqs7EJE"
      },
      "outputs": [],
      "source": [
        "# Importing Pre-requisites\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, AveragePooling2D, GlobalAveragePooling2D\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet import ResNet50\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = pd.read_csv('/content/labels.csv')"
      ],
      "metadata": {
        "id": "wYqvs33p7RGu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "WXwZrB3862dF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir Images"
      ],
      "metadata": {
        "id": "kMwc_aQZ65X-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "images = \"/content/final_files (1).zip\"\n",
        "with ZipFile(images, 'r') as zip:\n",
        "  zip.printdir()\n",
        "  zip.extractall('Images')\n",
        "  print('Done!')\n"
      ],
      "metadata": {
        "id": "w_8EEv4R68ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "dataframe=labels,\n",
        "directory='/content/Images/final_files',\n",
        "x_col=\"file_name\",\n",
        "y_col=\"real_age\",\n",
        "subset=\"training\",\n",
        "batch_size=32,\n",
        "seed=12345,\n",
        "shuffle=False,\n",
        "class_mode=\"raw\",\n",
        "target_size=(100,100)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQvUDbLB7ZSF",
        "outputId": "120f1e57-bbe9-4e12-ecb4-3c5d25536749"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7591 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                  validation_split=0.2)\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=labels,\n",
        "        directory='/content/Images/final_files',\n",
        "        x_col='file_name',\n",
        "        y_col='real_age',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='raw',\n",
        "        subset='validation',\n",
        "        seed=12345)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8ZU5YRP9J5c",
        "outputId": "d319e9b9-0285-4f3b-8980-4bd1aabec680"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1518 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(learning_rate = 0.0001)\n",
        "backbone = ResNet50(input_shape=(224, 224, 3),\n",
        "                        weights='imagenet', \n",
        "                        include_top=False)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(backbone)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(1, activation='relu'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ryZ9AUn9P52",
        "outputId": "a24f090b-91ae-4ed6-9978-553c32564dfd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_generator, test_generator,batch_size=None,epochs=5, steps_per_epoch =None, validation_steps=None):\n",
        "    my_callbacks = [ tf.keras.callbacks.EarlyStopping(patience=35)] \n",
        "    if steps_per_epoch is None:\n",
        "        steps_per_epoch = len(train_generator)\n",
        "    if validation_steps is None:\n",
        "        validation_steps = len(test_generator)\n",
        "    model.fit(train_generator,\n",
        "          validation_data=test_generator,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          validation_steps=validation_steps,\n",
        "          verbose=1, epochs=epochs,  callbacks=my_callbacks)\n",
        "    return model"
      ],
      "metadata": {
        "id": "UvdZFv4i9U1t"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = train_model(model, train_generator, test_generator,batch_size=None,epochs=5, steps_per_epoch =None, validation_steps=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyYpmfd59Zn1",
        "outputId": "ee51e07d-78d4-4ba0-e954-bec54b3abd9a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "238/238 [==============================] - 1841s 8s/step - loss: 256.4859 - mae: 11.6996 - val_loss: 385.3423 - val_mae: 14.6495\n",
            "Epoch 2/5\n",
            "238/238 [==============================] - 1850s 8s/step - loss: 73.8100 - mae: 6.5781 - val_loss: 586.0945 - val_mae: 19.0746\n",
            "Epoch 3/5\n",
            "238/238 [==============================] - 1762s 7s/step - loss: 38.4843 - mae: 4.7476 - val_loss: 346.6274 - val_mae: 13.9519\n",
            "Epoch 4/5\n",
            "238/238 [==============================] - 1793s 8s/step - loss: 23.3197 - mae: 3.7284 - val_loss: 329.6147 - val_mae: 13.8466\n",
            "Epoch 5/5\n",
            "238/238 [==============================] - 1798s 8s/step - loss: 15.5946 - mae: 3.0076 - val_loss: 335.4835 - val_mae: 14.2175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The process took too long per Epoch averaging 8s/step "
      ],
      "metadata": {
        "id": "NcF9rYWFeayc"
      }
    }
  ]
}